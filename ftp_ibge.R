# Carregar bibliotecas necessÃ¡rias
library(rvest)
library(httr)
library(dplyr)
library(stringr)
library(readr)

# FunÃ§Ã£o para extrair informaÃ§Ãµes de uma pÃ¡gina FTP
extrair_conteudo_ftp <- function(url) {
  tryCatch({
    cat("  â†’ Acessando:", url, "\n")
    
    # Fazer requisiÃ§Ã£o HTTP com timeout maior
    response <- GET(url, timeout(60))
    
    # Verificar se a requisiÃ§Ã£o foi bem-sucedida
    if (status_code(response) != 200) {
      cat("    âŒ Erro HTTP:", status_code(response), "\n")
      return(data.frame())
    }
    
    # Parsear o HTML
    page <- read_html(response)
    
    # MÃ©todo 1: Tentar extrair de <pre> (formato tÃ­pico de FTP)
    pre_content <- page %>% html_nodes("pre") %>% html_text()
    
    if (length(pre_content) > 0 && nchar(pre_content[1]) > 100) {
      return(processar_pre_ftp(pre_content[1], url))
    }
    
    # MÃ©todo 2: Extrair links diretamente
    links <- page %>% html_nodes("a") %>% html_attr("href")
    texts <- page %>% html_nodes("a") %>% html_text()
    
    if (length(links) > 0) {
      # Filtrar links vÃ¡lidos
      valid_indices <- !is.na(links) & 
        !links %in% c("../", "./", "/") & 
        !str_detect(links, "^http") &
        !str_detect(links, "^mailto") &
        !str_detect(links, "\\?")
      
      links <- links[valid_indices]
      texts <- texts[valid_indices]
      
      if (length(links) > 0) {
        df <- data.frame(
          nome = texts,
          tipo = ifelse(str_detect(links, "/$"), "diretorio", "arquivo"),
          data_modificacao = NA,
          tamanho = NA,
          url_completa = paste0(url, links),
          stringsAsFactors = FALSE
        )
        
        cat("    âœ… Encontrados", nrow(df), "itens\n")
        return(df)
      }
    }
    
    cat("    âš ï¸ Nenhum conteÃºdo encontrado\n")
    return(data.frame())
    
  }, error = function(e) {
    cat("    âŒ Erro:", e$message, "\n")
    return(data.frame())
  })
}

# FunÃ§Ã£o para processar conteÃºdo de <pre> do FTP
processar_pre_ftp <- function(pre_text, base_url) {
  lines <- strsplit(pre_text, "\n")[[1]]
  lines <- lines[!str_detect(lines, "^\\s*$|Parent Directory|Index of|Busque no|Portal IBGE|Downloads")]
  lines <- lines[str_detect(lines, "\\S")]  # Linhas nÃ£o vazias
  
  dados <- data.frame()
  
  for (line in lines) {
    # Tentar diferentes padrÃµes de parsing
    if (str_detect(line, "\\d{4}-\\d{2}-\\d{2}")) {
      # Formato: Nome Data Tamanho DescriÃ§Ã£o
      parts <- str_split(str_trim(line), "\\s+")[[1]]
      
      if (length(parts) >= 3) {
        nome <- parts[1]
        data_mod <- paste(parts[2], ifelse(length(parts) >= 3, parts[3], ""))
        tamanho <- ifelse(length(parts) >= 4 && parts[4] != "-", parts[4], NA)
        
        # Detectar se Ã© diretÃ³rio
        tipo <- ifelse(str_detect(nome, "/$") || str_detect(line, "<DIR>"), "diretorio", "arquivo")
        
        dados <- rbind(dados, data.frame(
          nome = nome,
          tipo = tipo,
          data_modificacao = str_trim(data_mod),
          tamanho = tamanho,
          url_completa = paste0(base_url, nome),
          stringsAsFactors = FALSE
        ))
      }
    }
  }
  
  if (nrow(dados) > 0) {
    cat("    âœ… Processadas", nrow(dados), "linhas do FTP\n")
  }
  
  return(dados)
}

# FunÃ§Ã£o recursiva ILIMITADA para mapear toda a Ã¡rvore
mapear_arvore_ftp_completa <- function(url_base, visitados = character(), profundidade_atual = 0) {
  
  # Evitar loops infinitos
  if (url_base %in% visitados) {
    cat("ğŸ”„ URL jÃ¡ visitada, pulando:", url_base, "\n")
    return(data.frame())
  }
  
  # Adicionar Ã  lista de visitados
  visitados <- c(visitados, url_base)
  
  # Log de progresso
  indent <- paste(rep("  ", profundidade_atual), collapse = "")
  cat(indent, "ğŸ“ NÃ­vel", profundidade_atual, ":", url_base, "\n")
  
  # Extrair conteÃºdo da URL atual
  conteudo <- extrair_conteudo_ftp(url_base)
  
  if (nrow(conteudo) == 0) {
    cat(indent, "  âš ï¸ Nenhum conteÃºdo encontrado\n")
    return(data.frame())
  }
  
  # Adicionar metadados
  conteudo$profundidade <- profundidade_atual
  conteudo$caminho_pai <- url_base
  conteudo$timestamp_coleta <- Sys.time()
  
  # Contador de progresso
  total_itens <- nrow(conteudo)
  cat(indent, "  ğŸ“Š Total de itens:", total_itens, "\n")
  
  # Identificar diretÃ³rios para recursÃ£o
  subdiretorios <- conteudo[conteudo$tipo == "diretorio", ]
  
  resultado_completo <- conteudo
  
  # Processar TODOS os subdiretÃ³rios recursivamente
  if (nrow(subdiretorios) > 0) {
    cat(indent, "  ğŸ“‚ Processando", nrow(subdiretorios), "subdiretÃ³rios...\n")
    
    for (i in 1:nrow(subdiretorios)) {
      subdir_nome <- subdiretorios$nome[i]
      subdir_url <- subdiretorios$url_completa[i]
      
      cat(indent, "    [", i, "/", nrow(subdiretorios), "] Processando:", subdir_nome, "\n")
      
      # Pausa para nÃ£o sobrecarregar o servidor
      Sys.sleep(0.5)
      
      # RecursÃ£o com lista de visitados atualizada
      sub_resultado <- mapear_arvore_ftp_completa(
        subdir_url, 
        visitados, 
        profundidade_atual + 1
      )
      
      if (nrow(sub_resultado) > 0) {
        resultado_completo <- rbind(resultado_completo, sub_resultado)
        cat(indent, "    âœ… Adicionados", nrow(sub_resultado), "itens do subdiretÃ³rio\n")
      }
      
      # Atualizar visitados para prÃ³ximas iteraÃ§Ãµes
      visitados <- unique(c(visitados, sub_resultado$caminho_pai))
    }
  }
  
  cat(indent, "âœ… ConcluÃ­do nÃ­vel", profundidade_atual, "- Total coletado:", nrow(resultado_completo), "itens\n")
  return(resultado_completo)
}

# FunÃ§Ã£o principal otimizada
main_completo <- function() {
  # URL base do FTP do IBGE
  url_base <- "https://ftp.ibge.gov.br/"
  
  cat("ğŸš€ Iniciando mapeamento COMPLETO do FTP do IBGE...\n")
  cat("âš ï¸  ATENÃ‡ÃƒO: Este processo pode levar HORAS dependendo do tamanho do FTP!\n")
  cat("ğŸ“Š Progresso serÃ¡ mostrado em tempo real...\n\n")
  
  # Registrar tempo de inÃ­cio
  inicio <- Sys.time()
  
  # Mapear TODA a Ã¡rvore sem limitaÃ§Ã£o de profundidade
  arvore_completa <- mapear_arvore_ftp_completa(url_base)
  
  # Tempo total
  tempo_total <- Sys.time() - inicio
  
  if (nrow(arvore_completa) > 0) {
    cat("\nğŸ‰ MAPEAMENTO CONCLUÃDO!\n")
    cat("â±ï¸  Tempo total:", round(tempo_total, 2), attr(tempo_total, "units"), "\n")
    cat("ğŸ“Š Total de itens mapeados:", nrow(arvore_completa), "\n")
    
    # Enriquecer dados
    arvore_completa <- arvore_completa %>%
      mutate(
        # Calcular nÃ­vel baseado na URL
        nivel = str_count(url_completa, "/") - 3, # Ajustar contagem
        
        # CategorizaÃ§Ã£o mais detalhada
        categoria = case_when(
          str_detect(nome, "(?i)censo") ~ "Censos",
          str_detect(nome, "(?i)economia|pib|renda") ~ "Economia",
          str_detect(nome, "(?i)estatistica") ~ "EstatÃ­sticas",
          str_detect(nome, "(?i)populacao|demografia") ~ "Demografia",
          str_detect(nome, "(?i)perfil") ~ "Perfis",
          str_detect(nome, "(?i)educacao") ~ "EducaÃ§Ã£o",
          str_detect(nome, "(?i)saude") ~ "SaÃºde",
          str_detect(nome, "(?i)trabalho|emprego") ~ "Trabalho",
          str_detect(nome, "(?i)industria") ~ "IndÃºstria",
          str_detect(nome, "(?i)agricultura|agro") ~ "AgropecuÃ¡ria",
          TRUE ~ "Outros"
        ),
        
        # ExtensÃ£o do arquivo
        extensao = ifelse(tipo == "arquivo", 
                          str_extract(nome, "\\.[^.]+$"), 
                          NA),
        
        # Tamanho da URL (indicador de profundidade)
        profundidade_url = nchar(url_completa)
      ) %>%
      arrange(profundidade, caminho_pai, nome)
    
    # Salvar arquivo principal
    nome_arquivo <- paste0("arvore_ftp_ibge_COMPLETA_", 
                           format(Sys.Date(), "%Y%m%d_%H%M"), 
                           ".csv")
    
    # write_csv(arvore_completa, nome_arquivo, locale = locale(encoding = "UTF-8"))
    write.csv2(x = arvore_completa,file = nome_arquivo,fileEncoding = "UTF-8",row.names = F)
    cat("ğŸ’¾ Arquivo principal salvo:", nome_arquivo, "\n")
    
    # EstatÃ­sticas detalhadas
    cat("\nğŸ“ˆ ESTATÃSTICAS DETALHADAS:\n")
    
    # Por tipo
    estatisticas_tipo <- arvore_completa %>%
      count(tipo, name = "quantidade") %>%
      mutate(percentual = round(quantidade/sum(quantidade)*100, 1))
    
    cat("\nğŸ“ Por tipo:\n")
    print(estatisticas_tipo)
    
    # Por categoria
    estatisticas_categoria <- arvore_completa %>%
      count(categoria, sort = TRUE) %>%
      mutate(percentual = round(n/sum(n)*100, 1))
    
    cat("\nğŸ·ï¸  Por categoria:\n")
    print(head(estatisticas_categoria, 10))
    
    # Por profundidade
    estatisticas_profundidade <- arvore_completa %>%
      count(profundidade, name = "quantidade") %>%
      arrange(profundidade)
    
    cat("\nğŸ“Š Por nÃ­vel de profundidade:\n")
    print(estatisticas_profundidade)
    
    # Salvar estatÃ­sticas
    write_csv(estatisticas_tipo, paste0("stats_tipo_", nome_arquivo))
    write_csv(estatisticas_categoria, paste0("stats_categoria_", nome_arquivo))
    write_csv(estatisticas_profundidade, paste0("stats_profundidade_", nome_arquivo))
    
    # Top 20 diretÃ³rios com mais arquivos
    top_diretorios <- arvore_completa %>%
      filter(tipo == "arquivo") %>%
      count(caminho_pai, sort = TRUE) %>%
      head(20)
    
    cat("\nğŸ† Top 20 diretÃ³rios com mais arquivos:\n")
    print(top_diretorios)
    
    return(arvore_completa)
    
  } else {
    cat("\nâŒ FALHA: Nenhum dado foi coletado!\n")
    cat("ğŸ” Verifique:\n")
    cat("   - ConexÃ£o com internet\n")
    cat("   - Disponibilidade do servidor IBGE\n")
    cat("   - Estrutura do site (pode ter mudado)\n")
    return(NULL)
  }
}

# EXECUTAR O MAPEAMENTO COMPLETO
cat("âš ï¸  ÃšLTIMO AVISO: Este processo pode ser MUITO longo!\n")
cat("ğŸ’¡ Pressione Ctrl+C a qualquer momento para parar.\n")
cat("ğŸ”„ Iniciando em 5 segundos...\n\n")

Sys.sleep(5)

resultado_completo <- main_completo()

# AnÃ¡lise rÃ¡pida se houver dados
if (!is.null(resultado_completo) && nrow(resultado_completo) > 0) {
  cat("\nğŸ” PRÃ‰VIA DOS RESULTADOS:\n")
  
  # Mostrar estrutura
  cat("\nğŸ“‹ Estrutura dos dados:\n")
  str(resultado_completo)
  
  # Primeiras e Ãºltimas linhas
  cat("\nğŸ” Primeiras 5 linhas:\n")
  print(head(resultado_completo, 5))
  
  cat("\nğŸ”š Ãšltimas 5 linhas:\n")
  print(tail(resultado_completo, 5))
  
  # Arquivo mais profundo
  mais_profundo <- resultado_completo[which.max(resultado_completo$profundidade), ]
  cat("\nğŸ”ï¸  Item mais profundo (nÃ­vel", mais_profundo$profundidade, "):\n")
  cat("   ğŸ“", mais_profundo$nome, "\n")
  cat("   ğŸ”—", mais_profundo$url_completa, "\n")
}